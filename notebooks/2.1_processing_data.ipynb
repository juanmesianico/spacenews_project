{"cells":[{"cell_type":"markdown","source":["## Processing Raw Data"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"e63bff98-d5cf-49c7-bc6e-05ecf3fa0921"},{"cell_type":"code","source":["import re\n","import nltk\n","from nltk.corpus import stopwords\n","from pyspark.sql.functions import *\n","from pyspark.sql.types import *\n","nltk.download('stopwords', quiet=True)"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":19,"statement_ids":[19],"state":"finished","livy_statement_state":"available","spark_jobs_updating":false,"session_id":"ef1098ed-91b1-4951-bfcb-320f2cbecb22","normalized_state":"finished","queued_time":"2026-02-18T12:03:41.9188313Z","session_start_time":null,"execution_start_time":"2026-02-18T12:03:41.9199134Z","execution_finish_time":"2026-02-18T12:03:42.9360092Z","parent_msg_id":"fb8e20bd-2e2f-4d74-834b-48db541e6670"},"text/plain":"StatementMeta(, ef1098ed-91b1-4951-bfcb-320f2cbecb22, 19, Finished, Available, Finished, False)"},"metadata":{}},{"output_type":"execute_result","execution_count":49,"data":{"text/plain":"True"},"metadata":{}}],"execution_count":15,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"c1e7d1d4-f673-4e1f-9262-f0a6183795d0"},{"cell_type":"code","source":["import spacy\n","\n","nlp = spacy.load(\"en_core_web_sm\")"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":20,"statement_ids":[20],"state":"finished","livy_statement_state":"available","spark_jobs_updating":false,"session_id":"ef1098ed-91b1-4951-bfcb-320f2cbecb22","normalized_state":"finished","queued_time":"2026-02-18T12:03:53.2517587Z","session_start_time":null,"execution_start_time":"2026-02-18T12:03:53.2528392Z","execution_finish_time":"2026-02-18T12:03:54.1390129Z","parent_msg_id":"0d41e8fe-b97b-4dd0-94f3-f93c109885c2"},"text/plain":"StatementMeta(, ef1098ed-91b1-4951-bfcb-320f2cbecb22, 20, Finished, Available, Finished, False)"},"metadata":{}}],"execution_count":16,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"2b663476-e9ad-4069-8dc3-311371a76fa2"},{"cell_type":"code","source":["# STOPWORDS\n","STOPWORDS_EN = set(stopwords.words('english'))\n","CUSTOM_STOPWORDS = {\n","    'said', 'new', 'first', 'will', 'also', 'says',\n","    'may', 'could', 'would', 'one', 'two', 'three',\n","    'year', 'years', 'day', 'days', 'time', 'week',\n","    'month', 'months', 'get', 'make', 'take', 'go', 'appeared', 'post', 'after'\n","}\n","ALL_STOPWORDS = STOPWORDS_EN.union(CUSTOM_STOPWORDS)\n","\n","# KEYWORDS\n","TOPIC_KEYWORDS_backup = {\n","    \"Mars\": [\"mars\"],\n","    \"Moon\": [\"moon\", \"lunar\", \"artemis\", \"apollo\", \"selene\"],\n","    \"Space Launches\": [\"launch\", \"liftoff\", \"launched\", \"launching\", \"flight\", \"launches\",\"space\", \"missions\", \"mission\"],\n","    \"ISS\": [\"iss\", \"international\", \"station\", \"lab\"],\n","    \"SpaceX\": [\"spacex\", \"falcon\", \"dragon\", \"starship\", \"starlink\", \"elon\"],\n","    \"NASA\": [\"nasa\", \"astronaut\", \"astronauts\", \"nasa's\", \"center\", \"agency\", \"crew\"],\n","    \"Satellite\": [\"satellite\", \"satellites\", \"orbit\", \"orbital\", \"constellation\"],\n","    \"Rocket\": [\"rocket\", \"booster\", \"engine\", \"propulsion\"],\n","    \"Telescope\": [\"telescope\", \"webb\", \"hubble\", \"jwst\", \"observatory\"],\n","    \"China\": [\"china\", \"cnsa\", \"tiangong\", \"long march\"],\n","    \"Russia\": [\"russia\", \"roscosmos\", \"soyuz\", \"progress\"],\n","    \"Europe\": [\"esa\", \"european\", \"ariane\"],\n","    \"Commercial\": [\"commercial\", \"private\", \"tourism\", \"blue origin\", \"virgin galactic\"]\n","}\n","\n","TOPIC_KEYWORDS = {\n","    \"Launches\": [\n","        \"launch\", \"liftoff\", \"launched\", \"launching\", \"rocket launch\",\n","        \"maiden flight\", \"test flight\", \"orbital launch\", \"mission\", \"missions\"\n","    ],\n","    \"Spacecraft\": [\n","        \"spacecraft\", \"capsule\", \"vehicle\", \"starship\", \"dragon\",\n","        \"crew dragon\", \"cargo dragon\", \"soyuz\", \"starliner\"\n","    ],\n","    \"Rockets\": [\n","        \"rocket\", \"booster\", \"falcon\", \"ariane\", \"atlas\",\n","        \"delta\", \"electron\", \"vulcan\", \"long march\", \"sls\"\n","    ],\n","    \"ISS\": [\n","        \"iss\", \"international space station\", \"space station\",\n","        \"orbital laboratory\", \"spacewalk\", \"eva\"\n","    ],\n","    \"Moon\": [\n","        \"moon\", \"lunar\", \"artemis\", \"apollo\", \"selene\",\n","        \"south pole\"\n","    ],\n","    \"Mars\": [\n","        \"mars\", \"red planet\", \"martian\"\n","    ],\n","    \"Satellites\": [\n","        \"satellite\", \"satellites\", \"constellation\", \"starlink\",\n","        \"orbit\", \"orbital\", \"leo\", \"geostationary\"\n","    ],\n","    \"Space_Tourism\": [\n","        \"blue origin\", \"virgin galactic\", \"axiom space\",\n","        \"space tourist\", \"tourism\", \"suborbital\", \"private astronaut\", \"commercial\"\n","    ],\n","    \"NASA\": [\n","        \"nasa\", \"kennedy space center\", \"jpl\", \"johnson space center\",\n","        \"astronaut\", \"astronauts\", \"nasa's\", \"canaveral\", \"usa\"\n","    ],\n","    \"International\": [\n","        \"esa\", \"jaxa\", \"roscosmos\", \"cnsa\", \"isro\",\n","        \"european space agency\", \"arianespace\", \"china\", \"russia\"\n","    ],\n","    \"Science\": [\n","        \"telescope\", \"hubble\", \"webb\", \"jwst\", \"observatory\",\n","        \"exoplanet\", \"astronomy\", \"research\", \"discovery\"\n","    ],\n","    \"Technology\": [\n","        \"propulsion\", \"engine\", \"technology\", \"innovation\",\n","        \"reusable\", \"landing\", \"test\", \"development\"\n","    ]\n","}\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":21,"statement_ids":[21],"state":"finished","livy_statement_state":"available","spark_jobs_updating":false,"session_id":"ef1098ed-91b1-4951-bfcb-320f2cbecb22","normalized_state":"finished","queued_time":"2026-02-18T12:03:58.7587512Z","session_start_time":null,"execution_start_time":"2026-02-18T12:03:58.7600169Z","execution_finish_time":"2026-02-18T12:03:59.0727625Z","parent_msg_id":"bb100b52-700a-4291-9f2d-0c5d74f02593"},"text/plain":"StatementMeta(, ef1098ed-91b1-4951-bfcb-320f2cbecb22, 21, Finished, Available, Finished, False)"},"metadata":{}}],"execution_count":17,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"ece20867-e707-4d47-8276-b0add526e93d"},{"cell_type":"code","source":["# GENERAR TABLA TOPIC\n","rows = []\n","keyword_id = 1\n","\n","for category, keywords in TOPIC_KEYWORDS.items():\n","    for kw in keywords:\n","        rows.append((keyword_id, kw, category))\n","        keyword_id += 1\n","\n","rows.append((keyword_id, \"general\", \"General\"))\n","\n","topic_df = spark.createDataFrame(rows, [\"keyword_id\", \"keyword\", \"category\"])\n","topic_df.write.mode(\"overwrite\").format(\"delta\").saveAsTable(\"topic\")\n","print(f\"Tabla topic creada: {topic_df.count()} keywords en {len(TOPIC_KEYWORDS) + 1} categorías\")"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":22,"statement_ids":[22],"state":"finished","livy_statement_state":"available","spark_jobs_updating":false,"session_id":"ef1098ed-91b1-4951-bfcb-320f2cbecb22","normalized_state":"finished","queued_time":"2026-02-18T12:04:01.7400174Z","session_start_time":null,"execution_start_time":"2026-02-18T12:04:01.7410405Z","execution_finish_time":"2026-02-18T12:04:06.6564387Z","parent_msg_id":"3b933442-272d-4d4e-bee1-55b1e2299c3c"},"text/plain":"StatementMeta(, ef1098ed-91b1-4951-bfcb-320f2cbecb22, 22, Finished, Available, Finished, False)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Tabla topic creada: 96 keywords en 13 categorías\n"]}],"execution_count":18,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"4430d3a8-bf9b-4fc5-b757-0685b1177148"},{"cell_type":"code","source":["# FUNCIÓN DE EXTRACCIÓN DE ENTIDADES CON SPACY\n","# ============================================\n","\n","def extract_entities_spacy(text):\n","    \"\"\"\n","    Extrae entidades usando spaCy.\n","    \"\"\"\n","    if not text or len(text) < 5:\n","        return {\"organizations\": [], \"persons\": [], \"locations\": []}\n","    \n","    # Limitar texto para eficiencia\n","    text = text[:2000]\n","    \n","    organizations = []\n","    persons = []\n","    locations = []\n","    \n","    try:\n","        # Procesar texto con spaCy\n","        doc = nlp(text)\n","        \n","        # Extraer entidades reconocidas\n","        for ent in doc.ents:\n","            if ent.label_ == \"ORG\":\n","                organizations.append(ent.text)\n","            elif ent.label_ == \"PERSON\":\n","                persons.append(ent.text)\n","            elif ent.label_ in [\"GPE\", \"LOC\"]:\n","                locations.append(ent.text)\n","    \n","    except Exception as e:\n","        print(f\"Error en spaCy NER: {e}\")\n","        pass\n","\n","    # Lista de compañías espaciales clave que deben ser detectadas\n","    space_companies = [\n","        \"spacex\", \"virgin galactic\", \"roscosmos\", \"arianespace\",\n","        \"united launch alliance\", \"ula\", \"rocket lab\", \"astra\",\n","        \"relativity space\", \"axiom space\", \"northrop grumman\",\n","        \"lockheed martin\", \"boeing\", \"airbus\"\n","    ]\n","    \n","    text_lower = text.lower()\n","    \n","    # Buscar cada compañía con word boundaries\n","    for company in space_companies:\n","        pattern = r'\\b' + re.escape(company) + r'\\b'\n","        if re.search(pattern, text_lower):\n","            # Capitalizar correctamente\n","            company_capitalized = company.title()\n","            # Agregar solo si no está ya en la lista\n","            if company_capitalized not in organizations:\n","                organizations.append(company_capitalized)\n"," \n","    # Eliminar duplicados\n","    return {\n","        \"organizations\": list(set(organizations)),\n","        \"persons\": list(set(persons)),\n","        \"locations\": list(set(locations))\n","    }\n","\n","print(\"Función de extracción de entidades creada\")\n","\n","entity_schema = StructType([\n","    StructField(\"organizations\", ArrayType(StringType()), True),\n","    StructField(\"persons\", ArrayType(StringType()), True),\n","    StructField(\"locations\", ArrayType(StringType()), True)\n","])\n","\n","def extract_entities_wrapper(text):\n","    \"\"\"Wrapper para UDF de Spark.\"\"\"\n","    result = extract_entities_spacy(text)\n","    return (result[\"organizations\"], result[\"persons\"], result[\"locations\"])\n","\n","extract_entities_udf = udf(extract_entities_wrapper, entity_schema)\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":23,"statement_ids":[23],"state":"finished","livy_statement_state":"available","spark_jobs_updating":false,"session_id":"ef1098ed-91b1-4951-bfcb-320f2cbecb22","normalized_state":"finished","queued_time":"2026-02-18T12:04:09.4063387Z","session_start_time":null,"execution_start_time":"2026-02-18T12:04:09.407567Z","execution_finish_time":"2026-02-18T12:04:09.7244687Z","parent_msg_id":"ba885c1b-70a8-46ca-9247-e4fecbf839e6"},"text/plain":"StatementMeta(, ef1098ed-91b1-4951-bfcb-320f2cbecb22, 23, Finished, Available, Finished, False)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Función de extracción de entidades creada\n"]}],"execution_count":19,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"03f2dbc9-a6af-4114-bc84-09ba0d0b88d3"},{"cell_type":"code","source":["# FUNCIÓN OPTIMIZADA CON CARGA INCREMENTAL\n","def process_table(table_name, silver_name, topic_df):\n","    \"\"\"\n","    Procesa tabla Bronze → Silver con CARGA INCREMENTAL:\n","    - Solo procesa registros nuevos (no reprocesa histórico)\n","    - keyword_id (clasificación de tema)\n","    - companies (organizaciones detectadas)\n","    - people (personas detectadas)\n","    - places (lugares detectados)\n","    \"\"\"\n","    print(f\"\\n{'='*70}\")\n","    print(f\"Procesando: {table_name} → {silver_name}\")\n","    print(f\"{'='*70}\")\n","    \n","    # Leer Bronze\n","    df_bronze = spark.read.table(table_name)\n","    initial_count = df_bronze.count()\n","    print(f\"Registros totales en Bronze: {initial_count:,}\")\n","    \n","    # Identificar registros nuevos\n","    try:\n","        df_silver_existing = spark.read.table(silver_name)\n","        existing_ids = df_silver_existing.select(\"id\").distinct()\n","        \n","        # Left anti join — solo registros que NO están en silver\n","        df = df_bronze.join(existing_ids, \"id\", \"left_anti\")\n","        \n","        new_count = df.count()\n","        print(f\"Registros nuevos a procesar: {new_count:,}\")\n","        \n","        if new_count == 0:\n","            print(\"✓ No hay registros nuevos — omitiendo procesamiento\")\n","            return\n","    \n","    except Exception as e:\n","        # Primera ejecución — la tabla silver no existe\n","        print(f\"Primera carga detectada — procesando todos los registros\")\n","        df = df_bronze\n","    \n","    # Filtrar registros válidos\n","    df = df.filter(\n","        col(\"published_at\").isNotNull() &\n","        col(\"id\").isNotNull() &\n","        col(\"title\").isNotNull()\n","    )\n","    \n","    valid_count = df.count()\n","    print(f\"Registros válidos: {valid_count:,}\")\n","    \n","    if valid_count == 0:\n","        print(\"⚠ No hay registros válidos para procesar\")\n","        return\n","    \n","    # Parsear a tipo fecha y campos adicionales para partición\n","    df = df.withColumn(\"published_at\", to_date(\"published_at\")) \\\n","            .withColumn(\"updated_at\", to_date(\"updated_at\")) \\\n","            .withColumn(\"year\", year(\"published_at\")) \\\n","            .withColumn(\"month\", month(\"published_at\")) \\\n","            .withColumn(\"date_key\", date_format(col(\"published_at\"), \"yyyyMMdd\").cast(\"int\"))\n","    \n","    # PASO 1: CLASIFICACIÓN POR KEYWORD_ID\n","    # Crear full_text TEMPORAL (title cuenta doble)\n","    df_temp = df.withColumn(\n","        \"full_text_temp\",\n","        lower(concat_ws(\" \", col(\"title\"), col(\"title\"), col(\"summary\")))\n","    )\n","    \n","    # Filtrar nulls en full_text\n","    df_temp = df_temp.filter(col(\"full_text_temp\").isNotNull() & (col(\"full_text_temp\") != \"\"))\n","    \n","    # El DataFrame se reutiliza en clasificación y NER, por lo que se cachea\n","    df_temp.cache()\n","    cached_count = df_temp.count()\n","    print(f\"Registros cacheados para procesamiento: {cached_count:,}\")\n","    \n","    # Broadcast topic_df\n","    topic_broadcast = broadcast(topic_df)\n","    \n","    # Keywords ordenadas por longitud (más largas primero)\n","    topic_list = topic_broadcast.select(\"keyword_id\", \"keyword\").collect()\n","    keyword_id_list = [\n","        (row.keyword_id, row.keyword.lower()) \n","        for row in topic_list \n","        if row.keyword != \"general\"\n","    ]\n","    keyword_id_list.sort(key=lambda x: len(x[1]), reverse=True)\n","    \n","    # ID de General\n","    general_id = topic_df.filter(col(\"category\") == \"General\") \\\n","        .select(\"keyword_id\").collect()[0][0]\n","    \n","    # UDF de clasificación\n","    def get_primary_keyword_optimized(text):\n","        if not text:\n","            return general_id\n","        max_count = 0\n","        selected_id = general_id\n","        for kid, kw in keyword_id_list:\n","            pattern = r'\\b' + re.escape(kw) + r'\\b'\n","            matches = len(re.findall(pattern, text))\n","            if matches > max_count:\n","                max_count = matches\n","                selected_id = kid\n","        return selected_id\n","    \n","    udf_primary_keyword = udf(get_primary_keyword_optimized, IntegerType())\n","    \n","    # Aplicar clasificación\n","    df_with_keyword = df_temp.withColumn(\"keyword_id\", udf_primary_keyword(col(\"full_text_temp\")))\n","    \n","    # PASO 2: EXTRACCIÓN DE ENTIDADES (NER CON SPACY)\n","    # Crear texto para NER (title + summary sin duplicar)\n","    df_with_ner_text = df_with_keyword.withColumn(\n","        \"ner_text_temp\",\n","        concat_ws(\" \", col(\"title\"), col(\"summary\"))\n","    )\n","    \n","    # Aplicar NER con spaCy\n","    df_with_entities = df_with_ner_text.withColumn(\n","        \"entities_temp\",\n","        extract_entities_udf(col(\"ner_text_temp\"))\n","    )\n","    \n","    # Expandir struct en columnas separadas\n","    df_with_expanded = df_with_entities \\\n","        .withColumn(\"organizations\", col(\"entities_temp.organizations\")) \\\n","        .withColumn(\"related_people\", col(\"entities_temp.persons\")) \\\n","        .withColumn(\"places\", col(\"entities_temp.locations\"))\n","    \n","    # ELIMINAR todas las columnas temporales antes de guardar\n","    df_result = df_with_expanded.drop(\"full_text_temp\", \"ner_text_temp\", \"entities_temp\")\n","    \n","    # Transformar los campos con listas a strings separados por comas\n","    target_columns = [\"organizations\", \"related_people\", \"places\"]\n","    for col_name in target_columns:\n","        df_result = df_result.withColumn(\n","            col_name, \n","            concat_ws(\", \", col(col_name))\n","        )\n","    \n","    # Ya no se necesita el DataFrame cacheado, liberamos memoria\n","    df_temp.unpersist()\n","    \n","    # Guardar en silver con APPEND\n","    print(f\"Guardando {df_result.count():,} registros en {silver_name}...\")\n","    \n","    df_result.write \\\n","        .mode(\"append\") \\\n","        .format(\"delta\") \\\n","        .partitionBy(\"year\", \"month\") \\\n","        .option(\"mergeSchema\", \"true\") \\\n","        .saveAsTable(silver_name)\n","    \n","    print(f\"✓ Tabla {silver_name} actualizada exitosamente\")"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":24,"statement_ids":[24],"state":"finished","livy_statement_state":"available","spark_jobs_updating":false,"session_id":"ef1098ed-91b1-4951-bfcb-320f2cbecb22","normalized_state":"finished","queued_time":"2026-02-18T12:04:13.5918101Z","session_start_time":null,"execution_start_time":"2026-02-18T12:04:13.5933191Z","execution_finish_time":"2026-02-18T12:04:13.9994477Z","parent_msg_id":"0a15e6be-82d0-4e40-a49d-e1d4d01f1a55"},"text/plain":"StatementMeta(, ef1098ed-91b1-4951-bfcb-320f2cbecb22, 24, Finished, Available, Finished, False)"},"metadata":{}}],"execution_count":20,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"1fe8e42e-5da4-49a6-80a4-b4fc2cd1cf3f"},{"cell_type":"code","source":["silver_articles = process_table(\"bronze_articles\", \"silver_articles\", topic_df)\n","silver_blogs = process_table(\"bronze_blogs\", \"silver_blogs\", topic_df)\n","silver_reports = process_table(\"bronze_reports\", \"silver_reports\", topic_df)"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":25,"statement_ids":[25],"state":"finished","livy_statement_state":"available","spark_jobs_updating":false,"session_id":"ef1098ed-91b1-4951-bfcb-320f2cbecb22","normalized_state":"finished","queued_time":"2026-02-18T12:04:18.9552043Z","session_start_time":null,"execution_start_time":"2026-02-18T12:04:18.9563042Z","execution_finish_time":"2026-02-18T12:06:31.189784Z","parent_msg_id":"c289ea81-1e2d-4cb1-967e-7ff44599512d"},"text/plain":"StatementMeta(, ef1098ed-91b1-4951-bfcb-320f2cbecb22, 25, Finished, Available, Finished, False)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n======================================================================\nProcesando: bronze_articles → silver_articles\n======================================================================\nRegistros totales en Bronze: 32,192\nPrimera carga detectada — procesando todos los registros\nRegistros válidos: 32,192\nRegistros cacheados para procesamiento: 32,192\nGuardando 32,192 registros en silver_articles...\n✓ Tabla silver_articles actualizada exitosamente\n\n======================================================================\nProcesando: bronze_blogs → silver_blogs\n======================================================================\nRegistros totales en Bronze: 1,884\nPrimera carga detectada — procesando todos los registros\nRegistros válidos: 1,884\nRegistros cacheados para procesamiento: 1,884\nGuardando 1,884 registros en silver_blogs...\n✓ Tabla silver_blogs actualizada exitosamente\n\n======================================================================\nProcesando: bronze_reports → silver_reports\n======================================================================\nRegistros totales en Bronze: 1,415\nPrimera carga detectada — procesando todos los registros\nRegistros válidos: 1,415\nRegistros cacheados para procesamiento: 1,415\nGuardando 1,415 registros en silver_reports...\n✓ Tabla silver_reports actualizada exitosamente\n"]}],"execution_count":21,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"81823783-3a4b-4914-b4f7-d9f19b59f885"}],"metadata":{"kernel_info":{"name":"synapse_pyspark"},"kernelspec":{"name":"synapse_pyspark","display_name":"synapse_pyspark"},"language_info":{"name":"python"},"microsoft":{"language":"python","language_group":"synapse_pyspark","ms_spell_check":{"ms_spell_check_language":"es"}},"nteract":{"version":"nteract-front-end@1.0.0"},"synapse_widget":{"version":"0.1","state":{}},"spark_compute":{"compute_id":"/trident/default","session_options":{"conf":{"spark.synapse.nbs.session.timeout":"1200000"}}},"dependencies":{"lakehouse":{"default_lakehouse":"09caa291-8a16-427c-bb94-bd1c6c9834a7","known_lakehouses":[{"id":"09caa291-8a16-427c-bb94-bd1c6c9834a7"}],"default_lakehouse_name":"spaceflight_lakehouse","default_lakehouse_workspace_id":"791923fa-337f-43ca-a8de-e686227363ea"},"environment":{"environmentId":"bdde589a-623e-4185-aac2-34f93ea1b6ac","workspaceId":"791923fa-337f-43ca-a8de-e686227363ea"}}},"nbformat":4,"nbformat_minor":5}